# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'se1.ui'
#
# Created by: PyQt5 UI code generator 5.15.6
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.
import os
import pandas as pd
import tensorflow as tf
import numpy as np
import pickle
#Import the modules
import text2emotion as te
from textblob import TextBlob

df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train2.csv'))
df.head()

from tensorflow.keras.layers import TextVectorization

X = df['comment_text'].astype(str)#.apply(pd.to_numeric) 
y = df[df.columns[2:]].values
#X_train["x3"] = X_train["x3"]
#tf.convert_to_tensor(X, dtype=tf.float32)
print(X.dtypes)

MAX_FEATURES = 200000 # number of words in the vocab

vectorizer = TextVectorization(max_tokens=MAX_FEATURES,
                               output_sequence_length=1800,
                               output_mode='int')
							   
vectorizer.adapt(X.values)
vectorized_text = vectorizer(X.values)

#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file
dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))
dataset = dataset.cache()
dataset = dataset.shuffle(160000)
dataset = dataset.batch(16)
dataset = dataset.prefetch(8) # helps bottlenecks

train = dataset.take(int(len(dataset)*.7))
val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))
test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding

model = Sequential()
# Create the embedding layer 
model.add(Embedding(MAX_FEATURES+1, 32))
# Bidirectional LSTM Layer
model.add(Bidirectional(LSTM(32, activation='tanh')))
# Feature extractor Fully connected layers
model.add(Dense(128, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
# Final layer 
model.add(Dense(5, activation='sigmoid'))

model.compile(loss='BinaryCrossentropy', optimizer='Adam')

model.summary()
filename = 'model/finalized_model.h5'
history = None
try:
    #history = pickle.load(open(filename, 'rb'))
    #result = loaded_model.score(X_test, Y_test)
    print("Loading model")
    history = tf.keras.models.load_model(filename )
    #result = history.score(X_test, Y_test)
    print("Loaded Model")
except Exception as e:
    print(e)
    history = model.fit(train, epochs=10, validation_data=val)
    #pickle.dump(history, open(filename, 'wb'))
    model.save(filename)


translated = "I am anguished"
input_text = vectorizer(translated)
print(translated)
df.columns[2:]

res = history.predict(np.expand_dims(input_text, 0))
print(res)